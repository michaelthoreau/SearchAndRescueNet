{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SaRNet train-test",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki5einzWsQzw"
      },
      "source": [
        "# SaRNet: A Dataset for Deep Learning Assisted Search and Rescue with Satellite Imagery\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDskp4_1swB1"
      },
      "source": [
        "**Abstract**\n",
        "\n",
        " Access to high resolution satellite imagery has dramatically increased in recent years as several new constellations have entered service. High revisit frequencies as well as improved resolution has widened the use cases of satellite imagery to areas such as humanitarian relief and even Search and Rescue (SaR). We propose a novel remote sensing object detection dataset for deep learning assisted SaR. This dataset contains only very small objects that have been identified as potential targets in a live search and rescue scenario. We evaluate the application of popular object detection frameworks to this dataset as a baseline to inform further research. We also propose a novel object detection metric, specifically designed to be used in a deep learning assisted SaR setting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx_7k3FdsyTH"
      },
      "source": [
        "## Download the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dff6yoBQCfDU"
      },
      "source": [
        "!wget https://michaeltpublic.s3.amazonaws.com/sarnet.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqXfd5I5Cnc_"
      },
      "source": [
        "!unzip -q -o sarnet.zip "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jJ-TAYQtOgt"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76dKSwwoFmhU"
      },
      "source": [
        "# installing detectron2 with torch version 1.9\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.9\")   # check the torch version is the default, this may require changing in the future\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu102/torch1.9/index.html\n",
        "\n",
        "# after install you need to restart the runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZk_Larh353j"
      },
      "source": [
        "# Setup Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDMhazr0FxF-"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "try:\n",
        "  register_coco_instances(\"dataset_train_1\", {}, \"/content/dataset/annotations/train.json\", \"/content/dataset/train\")\n",
        "  register_coco_instances(\"dataset_val_1\", {}, \"/content/dataset/annotations/val.json\", \"/content/dataset/val\")\n",
        "  register_coco_instances(\"dataset_test_1\", {}, \"/content/dataset/annotations/test.json\", \"/content/dataset/test\")\n",
        "except AssertionError:\n",
        "  print(\"INFO: Datasets already registered.\")\n",
        "\n",
        "para_metadata = MetadataCatalog.get(\"dataset_train_1\")\n",
        "dataset_dicts = DatasetCatalog.get(\"dataset_train_1\")\n",
        "\n",
        "para_metadata_val = MetadataCatalog.get(\"dataset_val_1\")\n",
        "dataset_dicts_val = DatasetCatalog.get(\"dataset_val_1\")\n",
        "\n",
        "para_metadata_test = MetadataCatalog.get(\"dataset_test_1\")\n",
        "dataset_dicts_test = DatasetCatalog.get(\"dataset_test_1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc2gNDG23sG4"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJfyviQj-idI"
      },
      "source": [
        "from detectron2.engine.hooks import HookBase\n",
        "from detectron2.evaluation import inference_context\n",
        "from detectron2.utils.logger import log_every_n_seconds\n",
        "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
        "import detectron2.utils.comm as comm\n",
        "import torch\n",
        "import time\n",
        "import datetime\n",
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "class LossEvalHook(HookBase):\n",
        "    def __init__(self, eval_period, model, data_loader):\n",
        "        self._model = model\n",
        "        self._period = eval_period\n",
        "        self._data_loader = data_loader\n",
        "    \n",
        "    def _do_loss_eval(self):\n",
        "        # Copying inference_on_dataset from evaluator.py\n",
        "        total = len(self._data_loader)\n",
        "        num_warmup = min(5, total - 1)\n",
        "            \n",
        "        start_time = time.perf_counter()\n",
        "        total_compute_time = 0\n",
        "        losses = []\n",
        "        for idx, inputs in enumerate(self._data_loader):\n",
        "            if np.random.rand() > 0.1:\n",
        "              continue\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "            loss_batch = self._get_loss(inputs)\n",
        "            \n",
        "            losses.append(loss_batch)\n",
        "        mean_loss = np.mean(losses)\n",
        "        print(\"validation loss on 10% of val data: {}\".format(mean_loss))\n",
        "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
        "        comm.synchronize()\n",
        "\n",
        "        return losses\n",
        "            \n",
        "    def _get_loss(self, data):\n",
        "        # How loss is calculated on train_loop \n",
        "        metrics_dict = self._model(data)\n",
        "        metrics_dict = {\n",
        "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
        "            for k, v in metrics_dict.items()\n",
        "        }\n",
        "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
        "        return total_losses_reduced\n",
        "        \n",
        "        \n",
        "    def after_step(self):\n",
        "        next_iter = self.trainer.iter + 1\n",
        "        is_final = next_iter == self.trainer.max_iter\n",
        "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
        "            self._do_loss_eval()\n",
        "        self.trainer.storage.put_scalars(timetest=12)\n",
        "\n",
        "class MyTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "                     \n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.insert(-1,LossEvalHook(\n",
        "            cfg.TEST.EVAL_PERIOD_LOSS,\n",
        "            self.model,\n",
        "            build_detection_test_loader(\n",
        "                self.cfg,\n",
        "                self.cfg.DATASETS.TEST[0],\n",
        "                DatasetMapper(self.cfg,True)\n",
        "            )\n",
        "        ))\n",
        "        return hooks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOmPN7Mw7lD4"
      },
      "source": [
        "**faster_rcnn_R_50_DC5_3x.yaml**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fP5AUZIw7prE"
      },
      "source": [
        "# do configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml\"))\n",
        "cfg.OUTPUT_DIR = \"faster_rcnn_R_50_DC5_3x\"\n",
        "cfg.DATASETS.TRAIN = (\"dataset_train_1\",)\n",
        "cfg.DATASETS.TEST = (\"dataset_val_1\",)\n",
        "cfg.TEST.EVAL_PERIOD = 1000  # do a full coco evaluation every 500 iterations\n",
        "cfg.TEST.EVAL_PERIOD_LOSS = 500 # calculate the validation loss every 100 iterations\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_DC5_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.0001\n",
        "cfg.SOLVER.MAX_ITER = 5000\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.4]\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = MyTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxxZxwpVy1l"
      },
      "source": [
        "**faster_rcnn_R_50_C4_3x.yaml**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTw9iH8HTBHb"
      },
      "source": [
        "# do configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
        "cfg.OUTPUT_DIR = \"faster_rcnn_R_50_C4_3x.yaml\"\n",
        "cfg.DATASETS.TRAIN = (\"dataset_train_1\",)\n",
        "cfg.DATASETS.TEST = (\"dataset_val_1\",)\n",
        "cfg.TEST.EVAL_PERIOD = 1000  # do a full coco evaluation every 500 iterations\n",
        "cfg.TEST.EVAL_PERIOD_LOSS = 500 # calculate the validation loss every 100 iterations\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.0001\n",
        "cfg.SOLVER.MAX_ITER = 5000\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.4]\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = MyTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjZAsfCwWGsa"
      },
      "source": [
        "**faster_rcnn_R_50_FPN_3x.yaml**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fUGG9NLWFnM"
      },
      "source": [
        "# do configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.OUTPUT_DIR = \"faster_rcnn_R_50_FPN_3x.yaml\"\n",
        "cfg.DATASETS.TRAIN = (\"dataset_train_1\",)\n",
        "cfg.DATASETS.TEST = (\"dataset_val_1\",)\n",
        "cfg.TEST.EVAL_PERIOD = 1000  # do a full coco evaluation every 500 iterations\n",
        "cfg.TEST.EVAL_PERIOD_LOSS = 500 # calculate the validation loss every 100 iterations\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.0001\n",
        "cfg.SOLVER.MAX_ITER = 5000\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.4]\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "trainer = MyTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q17bMEfyboeE"
      },
      "source": [
        "## Evaluation\n",
        "The performance criteria for this application is less strict than for other applications, more false positives are acceptable. We will look at the number of predictions vs the recall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57SsTabCaeR7"
      },
      "source": [
        "%matplotlib inline\n",
        "para_metadata = MetadataCatalog.get(\"dataset_test_1\")\n",
        "dataset_dicts = DatasetCatalog.get(\"dataset_test_1\")\n",
        "import matplotlib.pyplot as plt\n",
        "for d in random.sample(dataset_dicts, 10):\n",
        "  img = cv2.imread(d[\"file_name\"])\n",
        "  \n",
        "  # Inference should use the config with parameters that are used in training\n",
        "  # cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "  cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.3   # set a custom testing threshold\n",
        "  cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.1\n",
        "  predictor = DefaultPredictor(cfg)\n",
        "  outputs = predictor(img)\n",
        "\n",
        "  # convert image for display only\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  v = Visualizer(img[:, :, ::-1], para_metadata)\n",
        "  v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "  fig = plt.figure(figsize=(15,15))\n",
        "  plt.imshow(v.get_image()[:, :, ::-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk9UcQhwbo_j"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from detectron2.structures import Boxes, BoxMode, pairwise_iou\n",
        "\n",
        "Nsamples = 50\n",
        "\n",
        "outputDirs = [\"faster_rcnn_R_50_FPN_3x.yaml\", \"faster_rcnn_R_50_C4_3x.yaml\", \"faster_rcnn_R_50_DC5_3x.yaml\"]\n",
        "modelNames = [\"faster_rcnn_R_50_FPN_3x\", \"faster_rcnn_R_50_C4_3x\", \"faster_rcnn_R_50_DC5_3x\"]\n",
        "\n",
        "\n",
        "gt_boxes = [[],[],[]]\n",
        "pred_boxes = [[],[],[]]\n",
        "pred_scores = [[],[],[]]\n",
        "for k, outputDir in enumerate(outputDirs):\n",
        "  for j,d in enumerate(random.sample(dataset_dicts, Nsamples)):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "\n",
        "    yamlFile = outputDir\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/\" + yamlFile))\n",
        "    cfg.OUTPUT_DIR = yamlFile\n",
        "   \n",
        "    # cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
        "    \n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
        "    cfg.MODEL.RPN.IOU_THRESHOLDS = [0.2, 0.4]\n",
        "\n",
        "    # Inference should use the config with parameters that are used in training\n",
        "    # cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "    cfg.MODEL.WEIGHTS = os.path.join(outputDir, \"model_final.pth\")  # path to the model we just trained\n",
        "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.01   # set a custom testing threshold\n",
        "    cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.1\n",
        "    predictor = DefaultPredictor(cfg)\n",
        "    outputs = predictor(img)\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "\n",
        "    gtBoxArray = np.zeros((len(d['annotations']), 4))\n",
        "\n",
        "    for i,annotation in enumerate(d['annotations']):\n",
        "      gtBoxArray[i] = np.array(annotation['bbox'])\n",
        "\n",
        "    # reformat ground truth boxes\n",
        "    gtBoxArray = BoxMode.convert(gtBoxArray, BoxMode.XYWH_ABS, BoxMode.XYXY_ABS)\n",
        "    \n",
        "    # prediction boxes - dont reformat\n",
        "    # predBoxArray = BoxMode.convert(instances.pred_boxes.tensor.numpy(), BoxMode.XYXY_ABS, BoxMode.XYWH_ABS)\n",
        "    predBoxArray = instances.pred_boxes.tensor.numpy()\n",
        "\n",
        "    gt_boxes[k].append(gtBoxArray)\n",
        "    pred_boxes[k].append(predBoxArray)\n",
        "    pred_scores[k].append(instances.scores.numpy())\n",
        "\n",
        "    print(\"testing: {}/{}\".format(j,Nsamples))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHNkymMxwNtd"
      },
      "source": [
        "#IoU threshold\n",
        "iou_threshold = 0.1\n",
        "\n",
        "ground_truth_boxes = np.zeros((len(outputDirs)))\n",
        "thresholds = np.linspace(0,1,100)\n",
        "correct_boxes = np.zeros((len(outputDirs),thresholds.shape[0]))\n",
        "prediction_boxes = np.zeros((len(outputDirs),thresholds.shape[0]))\n",
        "\n",
        "for k, outputDir in enumerate(outputDirs):\n",
        "  for j,t in enumerate(thresholds):\n",
        "    ground_truth_boxes[k] = 0\n",
        "    for i, (gtBoxArray, predBoxArray, scores) in enumerate(zip(gt_boxes[k], pred_boxes[k], pred_scores[k])):\n",
        "      # print(\"{}------------------------------:\".format(i))\n",
        "      gtBoxObjs = Boxes(gtBoxArray)\n",
        "      predBoxObjs = Boxes(predBoxArray)\n",
        "      overlaps = np.array(pairwise_iou(predBoxObjs, gtBoxObjs))\n",
        "      # print(overlaps, scores)\n",
        "      ground_truth_boxes[k] += gtBoxArray.shape[0]\n",
        "      for score in scores:\n",
        "        if score >= t:\n",
        "          prediction_boxes[k][j] += 1\n",
        "\n",
        "      # check for a correct prediction for each gt box\n",
        "      for gt in range(overlaps.shape[1]):\n",
        "        for predOverlap, score in zip(overlaps[:,gt], scores):\n",
        "          # print(predOverlap, score)\n",
        "          if predOverlap > iou_threshold and score > t:\n",
        "            correct_boxes[k][j] += + 1\n",
        "\n",
        "print(ground_truth_boxes, prediction_boxes, correct_boxes)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wwjh8lfxxe6"
      },
      "source": [
        "modelNames = [\"faster_rcnn_R_50_FPN_3x\", \"faster_rcnn_R_50_C4_3x\", \"faster_rcnn_R_50_DC5_3x\"]\n",
        "\n",
        "\n",
        "fig = plt.figure()\n",
        "for k, outputDir in enumerate(modelNames):\n",
        "  plt.plot(thresholds, prediction_boxes[k]/(Nsamples*0.25))  \n",
        "\n",
        "plt.legend(modelNames)\n",
        "plt.xlim([0.05, 1.0])\n",
        "plt.ylim([-5, 100])\n",
        "plt.title(\"Detections Density - Faster R-CNN\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"Detections per sq km\")\n",
        "\n",
        "fig = plt.figure()\n",
        "for k, outputDir in enumerate(modelNames):\n",
        "  plt.plot(thresholds, 100*correct_boxes[k]/ground_truth_boxes[k])\n",
        "\n",
        "plt.legend(modelNames)\n",
        "plt.xlim([0.05, 1.0])\n",
        "plt.title(\"Recall on conservative labels - Faster R-CNN\")\n",
        "plt.ylabel(\"Recall %\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "\n",
        "\n",
        "styles = ['-', '--', '-.']\n",
        "\n",
        "fig, ax1 = plt.subplots()\n",
        "plt.title(\"Detection Density and Recall - Faster R-CNN Baseline\")\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Confidence Threshold')\n",
        "ax1.set_ylabel('Detections per sq km', color=color)\n",
        "for k, outputDir in enumerate(modelNames):\n",
        "  ax1.plot(thresholds, prediction_boxes[k]/(Nsamples*0.25), color=color, linestyle=styles[k])\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "ax1.set_xlim([0.01, 1.0])\n",
        "ax1.set_ylim([-5, 100])\n",
        "ax1.legend(modelNames)\n",
        "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
        "\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Recall %', color=color)  # we already handled the x-label with ax1\n",
        "\n",
        "for k, outputDir in enumerate(modelNames):\n",
        "  ax2.plot(thresholds, 100*correct_boxes[k]/ground_truth_boxes[k], color=color, linestyle=styles[k])\n",
        "\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "ax2.set_xlim([0.01, 1.0])\n",
        "ax2.set_ylim([-5, 100])\n",
        "ax2.legend(modelNames)\n",
        "plt.savefig(\"density_and_recall.png\", dpi=300)\n",
        "plt.savefig(\"density_and_recall.eps\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqUPiGpdEPdP"
      },
      "source": [
        "ARd20 = np.zeros((len(modelNames)))\n",
        "\n",
        "for l, outputDir in enumerate(modelNames):\n",
        "  gts = ground_truth_boxes[l]\n",
        "  correct = correct_boxes[l]\n",
        "  densities = np.array(prediction_boxes[l])/(Nsamples*0.25)\n",
        "  \n",
        "\n",
        "  # find the lowest threshold that corresponds to a density lower than k\n",
        "  for k in np.linspace(0,20, 21):\n",
        "    r = correct[densities < k]\n",
        "    if len(r) > 1:\n",
        "      # ARd20[l] += t[0]/20\n",
        "      r = 100*r[0]/gts\n",
        "      ARd20[l] += r/20\n",
        "\n",
        "\n",
        "\n",
        "for model, score in zip(modelNames, ARd20):\n",
        "  print(\"Model:      {:30s}   ARd-20: {:.2f}\".format(model, score))\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}